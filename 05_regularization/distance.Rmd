---
title: "Distance"
output: "html_document"
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
options(digits=3)
set.seed(1)
library(tidyverse)
library(caret)
library(dplyr)
library(dslabs)
library(rafalib)
library(gridExtra)
ds_theme_set()
```

In this lesson, we will explore the concept of distance in the context of machine learning, and how it applies to building models with multiple predictors. 

Distance measures play an important role in machine learning. A distance measure is an objective score that summarizes the relative difference between two objects. Most commonly, the two objects are rows of data that describe a subject (such as a person), or an event (such as a purchase, a claim, or a diagnosis).

Many of the analyses we perform with high-dimensional data relate directly or indirectly to distance. Many clustering and machine learning techniques rely on being able to define distance, using features or predictors. 

## Euclidean Distance

In machine learning and data analysis, various distance metrics are used depending on the nature of the data and the problem at hand. Euclidean distance is the most common, and most likely the most familiar to you too.

As a review, let's define the distance between two points, $A$ and $B$, on a Cartesian plane.

```{r,echo=FALSE,fig.cap=""}
# Set up plotting parameters
mypar()

# Create the plot
plot(c(0,1,1),c(0,0,1), pch=16, cex=2, xaxt="n", yaxt="n", xlab="", ylab="", bty="n", xlim=c(-0.25,1.25), ylim=c(-0.25,1.25))
lines(c(0,1,1,0), c(0,0,1,0))

# Add text annotations
text(0,.2,expression(paste('(A'[x]*',A'[y]*')')),cex=1.5)
text(1,1.2,expression(paste('(B'[x]*',B'[y]*')')),cex=1.5)
text(-0.1,0,"A",cex=2)
text(1.1,1,"B",cex=2)
```

The euclidean distance between $A$ and $B$ is:

$$\sqrt{ (A_x-B_x)^2 + (A_y-B_y)^2}$$

## K-means clustering

An example of a machine learning algorithm that makes use of distance very directly is K-Means clustering. The K-means algorithm can be used to partition a dataset into distinct groups, or clusters. 

The algorithm aims to minimize the distance between points within each cluster and their respective centroids, effectively grouping similar points together.

### How K-means works

1. Initialization: Choose the number of clusters ($K$) and randomly select ($K$) data points as initial centroids aka "means".
2. Assignment: Assign each data point to the nearest centroid based on Euclidean distance.
3. Update: Calculate new centroids as the mean of all points assigned to each cluster.
4. Iteration: Repeat the assignment and update steps until the centroids no longer change significantly or a maximum number of iterations is reached.

![](./images/kmeans.jpg)

### Example: Clustering Heart Rates of Adults and Pediatric Patients

We will create a bimodal distribution representing heart rates of adults and pediatric patients and apply K-Means clustering to identify the two distinct groups.

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate heart rate data for adults
adult_heart_rates <- rnorm(200, mean = 70, sd = 10)

# Generate heart rate data for pediatric patients
pediatric_heart_rates <- rnorm(200, mean = 110, sd = 15)

# Combine the two datasets to create a bimodal distribution
heart_rate_data <- tibble(heart_rate = c(adult_heart_rates, pediatric_heart_rates))

# Visualize the data
ggplot(heart_rate_data, aes(x = heart_rate)) +
  geom_histogram(binwidth = 5, fill = "blue", color = "black") +
  labs(title = "Heart Rate Data (Bimodal Distribution)", x = "Heart Rate", y = "Frequency")

# Apply K-means clustering with 2 clusters
kmeans_result <- kmeans(heart_rate_data, centers = 2, nstart = 20)

# Add the cluster assignments to the original data
heart_rate_data <- heart_rate_data %>% mutate(cluster = factor(kmeans_result$cluster))

# Visualize the clustered data
ggplot(heart_rate_data, aes(x = heart_rate, fill = cluster)) +
  geom_histogram(binwidth = 5, color = "black", position = "dodge") +
  labs(title = "K-Means Clustering of Heart Rates", x = "Heart Rate", y = "Frequency", fill = "Cluster")
```

While we explicitly stated a value for $K$ in this example, there are several methods that are used to automatically determine the number of clusters. We won't explore those methods here, but you can find plenty of resources on the web if you would like to do a deeper dive.

## Manhattan ("Taxicab") distance

Note that Euclidean distance isn't the only measure of distance, and often our choice of distance metric is an important consideration in the modelling process.

Another common measure of distance is the Manhattan distance, which measures the sum of the absolute differences between the coordinates of two points. 

Conceptually, you can think of Manhattan distance as the route your taxi would take through grid-based systems like city blocks.

![](./images/manhattan_distance.png)

We will learn more about the use cases for Euclidean and Manhattan distances later, when we explore regularization. The Manhattan distance is the concept behind the L1 norm (also known as the Manhattan norm or Taxicab norm) and the L2 norm is also known as the Euclidean norm.


## K-Nearest Neighbors

K-nearest neighbors (kNN) is another clustering algorithm where,for any point for which we want to predict a class, we look for the $k$ nearest points and then take an average of these points. 

Let's use the eICU data we've been using this week and add a another predictor, `heartrate`, to our models so that now we are using `apachescore` and `heartrate` to predict mortality. 

```{r load_data}
# Load the data
cohort <- read.csv("./eicu_cohort.csv")
features = c("apachescore", "heartrate")
```

Next, create our training and test sets:

```{r split_data}
# Split the data into training and testing sets
set.seed(50)
train_index <- createDataPartition(cohort$apachescore, times = 1, p = 0.7, list = FALSE)
train_set <- cohort[train_index, ]
test_set <- cohort[-train_index, ]
```

Let's use a logistic regression model as a baseline. Train (/fit) the model on the training set:

```{r fit_model}
# Fit the k regression model
log_model <- glm(actualhospitalmortality ~ apachescore + heartrate, data = train_set, family = binomial)
```

Now predict outcomes of patients in the test set:

```{r predict}
# Generate predicted probabilities for the test set using the logistic regression model
# Specify 'type = "response"' to obtain probabilities instead of log-odds
y_hat_test_prob <- predict(log_model, test_set[features], type="response")

# Convert the predicted probabilities into binary class predictions (0 or 1)
# Use a threshold of 0.5 to decide the class; probabilities >= 0.5 are rounded to 1, others to 0
y_hat_test_class = round(y_hat_test_prob,0)

# Create a confusion matrix to compare the predicted classes with the actual outcomes in the test set
tab <- table(pred = y_hat_test_class, truth = test_set$actualhospitalmortality)

# Output the confusion matrix and compute accuracy
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```

Now, lets compare to kNN. Let's start with the default $k = 5$

```{r}
# Fit a k-Nearest Neighbors model using the training data
# By default, the number of neighbors (k) will be set to 5
knn_model <- knn3(actualhospitalmortality ~ apachescore + heartrate, data = train_set)

# Predict the class probabilities for the test set using the fitted kNN model
# Extract the second column which contains the predicted probabilities for the positive class
f_hat <- predict(knn_model, newdata = test_set)[,2]

# Create a confusion matrix by rounding the predicted probabilities to binary values
# Compare predicted classes with the actual mortality outcomes in the test set
tab <- table(pred = round(f_hat), truth = test_set$actualhospitalmortality)

# Output the confusion matrix
confusionMatrix(tab)$tab
confusionMatrix(tab)$overall["Accuracy"]
```

We get slightly better accuracy and better sensitivity with $k$NN. 

Let's take a look at the decision boundary for our model. 

```{r, echo=FALSE, fig.width=10.5, fig.height=5.25, fig.align="center", message = FALSE, warning=FALSE}
# Define the range for apache score and heartrate
x_range <- seq(0, 225, length.out = 200)
y_range <- seq(0, 200, length.out = 200)

# Create a grid of all combinations of 'apachescore' and 'heartrate' values
p_x <- expand.grid(apachescore = x_range, heartrate = y_range)

# Use the kNN model to predict the probability of mortality for each point in the grid
# 'f_hat' represents the predicted probabilities
f_hat <- predict(knn_model, newdata = p_x)[,2]

# Create the first plot (g1) showing the decision boundary using a color gradient
g1 <- p_x %>% mutate(f_hat = f_hat) %>%
  ggplot(aes(apachescore, heartrate, fill = f_hat))  +
  scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) + 
  geom_raster() + 
  guides(fill=FALSE) +  
  stat_contour(aes(x=apachescore,y=heartrate,z=f_hat),data=p_x, breaks=c(0.5),color="black",lwd=1.5)

# Create the second plot (g2) showing the actual data points with the decision boundary
g2 <- ggplot(p_x) +
  geom_point(data=train_set, aes(x=apachescore, y=heartrate, fill=as.factor(actualhospitalmortality)), pch=21) + 
  stat_contour(aes(x=apachescore, y=heartrate,z=f_hat), breaks=c(0.5),color="black",lwd=1.5) +
  guides(fill=guide_legend(title="Mortality"))

# Arrange the two plots (g1 and g2) side by side in a single row
grid.arrange(g1,g2, nrow=1)
``` 


When $k=5$, we see some islands of blue in the red area and vice versa. This is due to what we call _over training_ or _overfitting_.


## Overfitting

Overfitting is at its worst when we set $k = 1$. In this case we will obtain nearly perfect accuracy in the training set because each point is used to predict itself. So perfect accuracy must happen by definition. However, the test set accuracy is actually worse than our logistic regression model.

```{r}
# Fit a k-Nearest Neighbors model using the training data
# We set k = 1 to consider the closest single neighbor for classification
knn_fit_1 <- knn3(actualhospitalmortality ~ apachescore + heartrate, data = train_set, k=1)

# Predict the class probabilities on the training set using the kNN model
f_hat <- predict(knn_fit_1, newdata = train_set)[,2]
tab <- table(pred = round(f_hat), truth = train_set$actualhospitalmortality)
confusionMatrix(tab)$overall["Accuracy"]

# Create a confusion matrix by rounding the predicted probabilities to binary values
# Compare predicted classes with the actual mortality outcomes in the training set
f_hat <- predict(knn_fit_1, newdata = test_set)[,2]
tab <- table(pred = round(f_hat), truth = test_set$actualhospitalmortality)
confusionMatrix(tab)$overall["Accuracy"]
```

We can see the overfitting problem in this figure where there are a lot of blue islands in the red area. 

```{r, echo=FALSE, fig.width=10.5,fig.height=5.25, fig.align="center", warning=FALSE}
# Predict the class probabilities for each point in the grid using the kNN model
# Extract the second column which contains the predicted probabilities for the positive class
f_hat <- predict(knn_fit_1, newdata = p_x)[,2]

# Create the first plot (g1) to visualize the predicted probabilities across the grid
g1 <- p_x %>% mutate(f_hat = f_hat) %>%
  ggplot(aes(apachescore, heartrate, fill = f_hat))  +
  scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) + geom_raster() +
  guides(fill=FALSE) +  
  stat_contour(aes(x=apachescore,y=heartrate,z=f_hat),data=p_x,breaks=c(0.5),color="black",lwd=1.5)

# Create the second plot (g2) to visualize the training data points with the decision boundary
g2 <- ggplot(p_x) +  
  geom_point(data=train_set, aes(x=apachescore, y=heartrate, fill=as.factor(actualhospitalmortality)),  pch=21) + 
  stat_contour(aes(apachescore,heartrate,z=f_hat), breaks=c(0.5),color="black",lwd=1.5) +
  guides(fill=guide_legend(title="Mortality"))
  
# Arrange the two plots (g1 and g2) side by side in a single row
grid.arrange(g1,g2, nrow=1)
``` 


With $k = 7$ we obtain what appears to be a decent estimate of the true $f$. There are still a couple of red islands in the red area, but it's as good as we'll get for this particular model using $k$NN.

```{r, echo=FALSE, fig.width=10.5,fig.height=5.25, fig.align="center", warning=FALSE}
# Fit a k-Nearest Neighbors model using the training data
# Set k = 7 to consider the 7 nearest neighbors for classification
knn_fit_7 <- knn3(actualhospitalmortality ~ apachescore + heartrate, data = train_set, k=7)

# Predict the class probabilities for each point in the grid using the kNN model
# Extract the second column which contains the predicted probabilities for the positive class
f_hat <- predict(knn_fit_7, newdata = p_x)[,2]

# Create the first plot (g1) to visualize the predicted probabilities across the grid
g1 <- p_x %>% mutate(f_hat = f_hat) %>%
  ggplot(aes(apachescore, heartrate, fill = f_hat))  +
  scale_fill_gradientn(colors=c("#F8766D","white","#00BFC4")) + 
  geom_raster() +
  guides(fill=FALSE) +  
  stat_contour(aes(x=apachescore,y=heartrate,z=f_hat),data=p_x, breaks=c(0.5),color="black",lwd=1.5)

# Create the second plot (g2) to visualize the training data points with the decision boundary
g2 <- ggplot(p_x) +  
  geom_point(data=train_set, aes(apachescore, heartrate, fill = as.factor(actualhospitalmortality)),pch=21) +
  stat_contour(aes(x=apachescore,y=heartrate,z=f_hat), breaks=c(0.5),color="black",lwd=1.5) +
  guides(fill=guide_legend(title="Mortality"))

# Arrange the two plots (g1 and g2) side by side in a single row
grid.arrange(g1,g2, nrow=1)  
``` 


```{r}
# Predict the class probabilities for the test set using the kNN model with k = 7
# Extract the second column which contains the predicted probabilities for the positive class
f_hat <- predict(knn_fit_7, newdata = test_set)[,2]

# Create a confusion matrix by rounding the predicted probabilities to binary values
# Compare predicted classes with the actual mortality outcomes in the test set
tab <- table(pred = round(f_hat), truth = test_set$actualhospitalmortality)

# Calculate and retrieve the accuracy of the kNN model on the test set
confusionMatrix(tab)$overall["Accuracy"]
```




